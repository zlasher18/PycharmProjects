# overhead
import numpy as np
import torch as t
import torch.nn as nn
from torch import optim
import matplotlib.pyplot as plt


# environment parameters
FRAME_TIME = 0.1  # time interval
GRAVITY_ACCEL = 0.12  # gravity constant
BOOST_ACCEL = 0.18  # thrust constant

# define system dynamics
class Dynamics(nn.Module):

    def __init__(self):
        super(Dynamics, self).__init__()

    def forward(self, state, action):
        """
        action[0] = thrust
        action[1] = rotational thrust
        state[0] = y
        state[1] = y_dot
        state[2] = x
        state[3] = x_dot
        state[4] = theta
        """
        # Apply gravity in y direction
        delta_state_gravity = t.tensor([0., -GRAVITY_ACCEL * FRAME_TIME, 0., 0., 0.])

        # Thrust in y and x direction, based on angle. Given in slack
        N = len(state)
        state_tensor = t.zeros((N, 5))
        state_tensor[:, 1] = t.cos(state[:, 4])
        state_tensor[:, 3] = -t.sin(state[:, 4])
        delta_state = BOOST_ACCEL * FRAME_TIME * t.mul(state_tensor, action[:, 0].reshape(-1, 1))

        # angle changes due to time, and rotational thrust
        d_state_theta = FRAME_TIME * t.mul(t.tensor([0., 0., 0., 0, -1.]), action[:, 1].reshape(-1, 1))
        # state changes due to changes in position and angle
        state = state + delta_state + delta_state_gravity + d_state_theta

        # Update state
        step_mat = t.tensor([[1., FRAME_TIME, 0., 0., 0.],
                                 [0., 1., 0., 0., 0.],
                                 [0., 0., 1., FRAME_TIME, 0.],
                                 [0., 0., 0., 1., 0.],
                                 [0., 0., 0., 0., 1.]])

        state = t.matmul(step_mat, state.T)
        # does not work unless state is transposed.
        return state.T

# a deterministic controller
class Controller(nn.Module):

    def __init__(self, dim_input, dim_hidden, dim_output):
        """
        dim_input: # of system states
        dim_output: # of actions
        dim_hidden:
        """
        # I did not change any of these^^
        super(Controller, self).__init__()
        self.network = nn.Sequential(
            nn.Linear(dim_input, dim_hidden),
            nn.Tanh(),
            nn.Linear(dim_hidden, dim_output),
            nn.Sigmoid())

    def forward(self, state):
        action = self.network(state)
        return action

# the simulator that rolls out x(1), x(2), ..., x(T)
class Simulation(nn.Module):

    def __init__(self, controller, dynamics, T, k):
        super(Simulation, self).__init__()
        self.state = self.initialize_state()
        self.controller = controller
        self.dynamics = dynamics
        self.T = T
        self.k = k
        self.theta_trajectory = t.empty((1, 0))
        self.u_trajectory = t.empty((1, 0))

    def forward(self, state):
        self.action_trajectory = []
        self.state_trajectory = []
        for _ in range(T):
            action = self.controller(state)
            state = self.dynamics(state, action)
            self.action_trajectory.append(action)
            self.state_trajectory.append(state)
        return self.error(state)

    @staticmethod
    def initialize_state():
        state = t.rand((k, 5)) # gives random starting points so controller can determine at various starting points.
        state[:, 1] = 0  # y_dot = 0 at start of simulation
        state[:, 3] = 0  # x_dot = 0 at start of simulation
        return t.tensor(state, requires_grad=False).float()

    def error(self, state):
        return t.sum(state**2)

# set up the optimizer
class Optimize:

    def __init__(self, simulation):
        self.simulation = simulation
        self.parameters = simulation.controller.parameters()
        self.optimizer = optim.LBFGS(self.parameters, lr=0.01)
        self.loss_list = []

    def step(self):
        def closure():
            loss = self.simulation(self.simulation.state)
            self.optimizer.zero_grad()
            loss.backward()
            return loss

        self.optimizer.step(closure)
        return closure()

    def train(self, epochs):
        for epoch in range(epochs):
            loss = self.step()
            self.loss_list.append(loss)
            print('[%d] loss: %.3f' % (epoch + 1, loss))
        self.visualize()

    def visualize(self):
        data = np.array([[self.simulation.state_trajectory[i][k].detach().numpy()
        for i in range(self.simulation.T)]
        for k in range(self.simulation.k)])
        for i in range(self.simulation.k):
            x = data[i, :, 0]
            y = data[i, :, 2]
            ydot = data[i, :, 1]
            xdot = data[i, :, 3]
            theta = data[i, :, 4]
            fig, axs = plt.subplots(2)
            axs[0].plot(x, y)
            axs[0].set_title('Rocket Position')
            axs[0].set_xlabel('X Position')
            axs[0].set_ylabel('Y Position')

            axs[1].plot(list(range(self.simulation.T)), theta)
            axs[1].set_title('Angle of Rocket')
            axs[1].set_xlabel('Time')
            axs[1].set_ylabel('Theta(rad)')
        plt.show()

# Now it's time to run the code!

k = 10  # number of random starting positions
T = 100  # number of time steps
dim_input = 5  # state space dimensions
dim_hidden = 6  # latent dimensions
dim_output = 2  # action space dimensions
d = Dynamics()  # define dynamics
c = Controller(dim_input, dim_hidden, dim_output)  # define controller
s = Simulation(c, d, T, k)  # define simulation
o = Optimize(s)  # define optimizer
o.train(100)  # solve the optimization problem
